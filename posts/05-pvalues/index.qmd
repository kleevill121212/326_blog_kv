---
title: "Mini Project 5"
---

# Advantages and Drawbacks of Using p-values

**Mathematical Statistics Mini Project 5**

Kobe Villeneuve

***Question 1***

I believe the author is referencing the point of focusing solely on statistical significance as a measure of validity for research. As mentioned in the opening statements of the paper, two of the ‘Don'ts’ can be summarized as: do not let the p-value sway you in either direction when determining whether something can be derived from the relationships discovered in research. When researchers focus too much on statistically significant relationships, discovery can be lost in that pursuit. I can see it in my research when parsing through volumes of data, searching for ‘significant’ relationships. While these correlations with strong significance bear some value to the research being done, it does not mean I should be discarding the work done that produced higher p-values. I see statistical thinking as using all of the tools in your statistical toolkit, with statistical significance being one of them. Other tools include intuition about the relationships at play, qualitative aspects of the data that may not be accurately explained by the numbers that represent them, and, of course, the complexity of the data. Statistical thinking involves thinking critically about your data and how it is produced. An example of this would be examining trade centrality and global influence. When I examine the relationship between these two sets, there is a clear and significant relationship. However, when I think critically about my ‘statistics’, I can see there is a strong internal impact of economic influence on global influence. So it is clear that, in a sense, these two categories are measuring something similar, so it dampens the significance of the relationship. Conversely, a relationship between trade centrality and GDP per capita was found to have no significance at all. However, this is largely since GDP per capita is an upward sloping trend over time for developed nations, and centrality varies very marginally. The insignificance of the regression analysis does not mean I should discard the analysis entirely, but rather think more about how I can measure the relationship differently. Case in point, I think what the authors are communicating here is that significance is a tool, to be used inharmony with other tools, to allow a statistician (or math honors student) to conduct meaningful research that produces insightful conclusions.

***Question 2***

I think that by the first portion of their statement, the author means the p-value communicates what needs to be received. If a reader understands how to interpret a p-value properly (if they took Stat 326, for example), then they would be able to make the proper association between the p-value and the data. To set a line in the sand and say “this side is significant” and “the other side is not” takes away from the richness of the findings. It creates a mental barrier for consumers of the literature or research to discard the insignificant findings, for the simple reason mentioned earlier in the paper of how entangled the statistical and plain English definitions of significance have become. When creating a boundary or a dichotomy, it removes the element of critical thinking when digesting information. It seems like you have already been told that the data is ‘good’ or ‘bad’ because of the connotations associated with words like significant or insignificant. The label creates the dichotomization because it creates the two groups. If you are under, you are safe, if you are over, then you are not. I think the author means that by creating these two groups, there is too much emphasis placed on the categorization and not enough on the rest of the analysis. This is something I encounter when doing my own research, because I have been taught what is ‘good’ and what is ‘bad’, or at least that is how I interpreted the dichotomy throughout my education. It stands to reason that one should deploy the toolkit I mentioned earlier to enhance their comprehension of data.

***Question 3***

I agree mostly with this claim presented by the authors. When deciding what to include in published research, findings need to be evaluated on relevance, depth of research, and quality of data. I think that if the data is collected in an unbiased manner, with a large sample size, and all qualitative factors point to the results being relevant, then the findings should be included. You can cook up any number of relationships that have a low p-value, which have nothing to dowith each other, if you examine the qualitative details of the data. Say, for example, we look at coffee consumption and broken bones, which somehow have a strong relationship with a low p-value. If you examine that qualitatively, or think critically about what you are looking at, I am sure you could conclude that you might want to include something more relevant in your publication. However, I do feel that by examining what kind of research you are doing, the error types in the context of the problem present a fair argument for caring about a p-value to a certain degree. If you want to err on the side of caution and bias more towards an error type that is less harmful, like the arsenic concentration example we have looked at, then considering the p-value may help you with that effort. So while I largely believe what the authors are telling us, I think that the p-value is a tool that can be useful at times to make certain decisions.

***Question 4***

I agree wholeheartedly with this statement. A one-size-fits-all approach rarely works for anything, statistics aside. When dealing with data, it is often messy, with a great deal of uncertainty at play. I believe that expecting the certainty of one approach that is best is not realistic. The ATOM method they describe makes sense, because it is more a way of thinking that strays away from the binary decision making of a silver bullet solution. I think that it will always be context-specific, since statistical analysis spreads across every single field in the world. You would not be able to follow the same set of rules when dealing with medical research as you would with consumer preferences for a certain type of fabric for shirts. The context will always alter the approach you have to take when making decisions about your results and interpretation of those results, thus, it is not a reasonable expectation to have one singular method or rule to dictate the usefulness of findings.

***Question 5***

The authors reference ‘statistical thoughtfulness’ as a way of creating an approach to statistical analysis that requires deeper thought in all aspects of conducting research. I think this thoughtfulness means to consider why you are analyzing something, how you will do it, how youwill collect the data, and how the results will impact the current thought on your topic. When you consider what has been done before you in addition to where the community stands on a topic, it frees you up to make a calculated approach to your methods. I’ll draw on a personal example to highlight what it means to be statistically thoughtful. When I was thinking about my research question, I needed to first determine what was out there on my topic. There was plenty of writing done on modelling trade networks, as well as more complex mathematical analysis to predict outcomes of certain systems. Once I knew this, I was able to sharpen and define my goal clearly as an exploratory study on the relationships that clique centrality has with other economic indicators. This freed me up to include all relevant economic indicators, because I knew that a study of this manner did not exist in the popular literature, so although only a few variables held statistical significance with each other, I was able to produce meaningful conclusions. My general interpretation of this thoughtfulness is being deliberate in your decision-making to ensure you are contributing to the broader community.

***Question 6***

I agree with the authors that there is a problem with the way statistical results are presented. I think that the problem which the authors are referencing is directly related to the interpretation of those who read it. By stating conclusions using significant or confident language, it overstates the certainty of the claim to the reader. If every person on Earth took statistics courses in their educational journey, it might be okay to leave things as they are. The challenge arises when folks with non-statistical backgrounds interpret the research improperly. I think the term ‘compatibility interval’ is also a bit misleading. I believe that adding an interpretation with probabilities, whether the null is true, could be easier for people to interpret, thus making things more digestible to a broader audience. Compatibility does not introduce much more than the other terms in my opinion, but stating things such as “There is a 70% chance that the diet reduces weight” provides the necessary color.

***Question 7***

![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeEoU50aTKczqI6KJqTot8KxxVH6lwBQEaAn9mriRa2AOSrENKlTEtQ1Xnsf3IkBqZrvx27Q8aq6qI4i2IC--TYkNjBwKbC9cJxhqIE8YlGyIP953ICGcsAYxCIHNEVJKhx7cD?key=Mwdw_eGw9IDNXDYpHwgrEKDl)

Found in Section 2, paragraph 4.

I find this quote particularly interesting because it feels paradoxical. It made me think about how you would measure the difference between significant and not significant. Maybe a null hypothesis that there is no difference, and an alternative that there is. If you conduct this test and it tells you that the difference is not statistically significant, do you even trust that interpretation? It challenges statistical significance by using statistical significance. I really like how ‘meta’ this quote felt. It also made me think about how you go about proving the validity of analysis. I think that thoughtfulness, openness, and modesty are all great practices in statistical reporting (and life in general). Pre-specified power, novelty, and other measures that you can evaluate also help in determining how you analyze your data - it just seems like quite a lot of legwork to make these adjustments, although I agree they should be made!
